@INPROCEEDINGS{9623309,
author={},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={[Title page i]},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Presents the title page of the proceedings record.},
keywords={},
doi={10.1109/VIS49827.2021.9623309},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623325,
author={},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={[Title page iii]},
year={2021},
volume={},
number={},
pages={3-3},
abstract={Presents the title page of the proceedings record.},
keywords={},
doi={10.1109/VIS49827.2021.9623325},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623290,
author={},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={[Copyright notice]},
year={2021},
volume={},
number={},
pages={4-4},
abstract={Presents the copyright information for the conference. May include reprint permission information.},
keywords={},
doi={10.1109/VIS49827.2021.9623290},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623304,
author={},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Table of Contents},
year={2021},
volume={},
number={},
pages={5-9},
abstract={Presents the table of contents/splash page of the proceedings record.},
keywords={},
doi={10.1109/VIS49827.2021.9623304},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623292,
author={},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Message from the VIS 2021 General Chairs},
year={2021},
volume={},
number={},
pages={10-10},
abstract={Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.},
keywords={},
doi={10.1109/VIS49827.2021.9623292},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623283,
author={},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={VIS 2021 Conference Committee},
year={2021},
volume={},
number={},
pages={11-13},
abstract={Provides a listing of current committee members and society officers.},
keywords={},
doi={10.1109/VIS49827.2021.9623283},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623279,
author={},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={VIS 2021 Steering Committee},
year={2021},
volume={},
number={},
pages={14-14},
abstract={Provides a listing of current committee members and society officers.},
keywords={},
doi={10.1109/VIS49827.2021.9623279},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623276,
author={},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={VIS 2021 Executive Committee},
year={2021},
volume={},
number={},
pages={15-15},
abstract={Provides a listing of current committee members and society officers.},
keywords={},
doi={10.1109/VIS49827.2021.9623276},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623281,
author={},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={VIS 2021 Area Curation Committee},
year={2021},
volume={},
number={},
pages={16-16},
abstract={Provides a listing of current committee members and society officers.},
keywords={},
doi={10.1109/VIS49827.2021.9623281},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623277,
author={},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={VIS 2021 Program Committee},
year={2021},
volume={},
number={},
pages={17-20},
abstract={Provides a listing of current committee members and society officers.},
keywords={},
doi={10.1109/VIS49827.2021.9623277},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623327,
author={Borkiewicz, Kalina and Shah, Viraj and Naiman, J.P. and Shen, Chuanyue and Levy, Stuart and Carpenter, Jeff},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={CloudFindr: A Deep Learning Cloud Artifact Masker for Satellite DEM Data},
year={2021},
volume={},
number={},
pages={1-5},
abstract={Artifact removal is an integral component of cinematic scientific visualization, and is especially challenging with big datasets in which artifacts are difficult to define. In this paper, we describe a method for creating cloud artifact masks which can be used to remove artifacts from satellite imagery using a combination of traditional image processing together with deep learning based on U-Net. Compared to previous methods, our approach does not require multi-channel spectral imagery but performs successfully on single-channel Digital Elevation Models (DEMs). DEMs are a representation of the topography of the Earth and have a variety applications including planetary science, geology, flood modeling, and city planning.},
keywords={Deep learning;Earth;Satellites;Image processing;Geology;Urban planning;Data visualization;cinematic scientific visualization;science communication;public outreach;broad impact;data visualization;data processing;machine learning;deep learning;u net;image processing;data preparation},
doi={10.1109/VIS49827.2021.9623327},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623303,
author={Yuan, Jun and Nov, Oded and Bertini, Enrico},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={An Exploration And Validation of Visual Factors in Understanding Classification Rule Sets},
year={2021},
volume={},
number={},
pages={6-10},
abstract={Rule sets are often used in Machine Learning (ML) as a way to communicate the model logic in settings where transparency and intelligibility are necessary. Rule sets are typically presented as a text-based list of logical statements (rules). Surprisingly, to date there has been limited work on exploring visual alternatives for presenting rules. In this paper, we explore the idea of designing alternative representations of rules, focusing on a number of visual factors we believe have a positive impact on rule readability and understanding. We then presents a user study exploring their impact. The results show that some design factors have a strong impact on how efficiently readers can process the rules while having minimal impact on accuracy. This work can help practitioners employ more effective solutions when using rules as a communication strategy to understand ML models.},
keywords={Visualization;Conferences;Computational modeling;Focusing;Machine learning;Ruman-centered computing;Visualization;Empirical studies in visualization},
doi={10.1109/VIS49827.2021.9623303},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623323,
author={Heer, Jeffrey},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Fast amp; Accurate Gaussian Kernel Density Estimation},
year={2021},
volume={},
number={},
pages={11-15},
abstract={Kernel density estimation (KDE) models a discrete sample of data as a continuous distribution, supporting the construction of visualizations such as violin plots, heatmaps, and contour plots. This paper draws on the statistics and image processing literature to survey efficient and scalable density estimation techniques for the common case of Gaussian kernel functions. We evaluate the accuracy and running time of these methods across multiple visualization contexts and find that the combination of linear binning and a recursive filter approximation by Deriche efficiently produces pixel-perfect estimates across a compelling range of kernel bandwidths.},
keywords={Measurement;Maximum likelihood detection;Matched filters;Shape;Data visualization;Estimation;Nonlinear filters;Kernel density estimation, Gaussian convolution, binning, approximation, performance, evaluation},
doi={10.1109/VIS49827.2021.9623323},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623268,
author={Tabatabai, Delyar and Ruangrotsakun, Anita and Irvine, Jed and Dodge, Jonathan and Shureih, Zeyad and Lam, Kin-Ho and Burnett, Margaret and Fern, Alan and Kahng, Minsuk},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={“Why did my AI agent lose?”: Visual Analytics for Scaling Up After-Action Review},
year={2021},
volume={},
number={},
pages={16-20},
abstract={How can we help domain-knowledgeable users who do not have expertise in AI analyze why an AI agent failed? Our research team previously developed a new structured process for such users to assess AI, called After-Action Review for AI (AAR/AI), consisting of a series of steps a human takes to assess an AI agent and formalize their understanding. In this paper, we investigate how the AAR/AI process can scale up to support reinforcement learning (RL) agents that operate in complex environments. We augment the AAR/AI process to be performed at three levels—episode-level, decision-level, and explanation-level—and integrate it into our redesigned visual analytics interface. We illustrate our approach through a usage scenario of analyzing why a RL agent lost in a complex real-time strategy game built with the StarCraft 2 engine. We believe integrating structured processes like AAR/AI into visualization tools can help visualization play a more critical role in AI interpretability.},
keywords={Visual analytics;Conferences;Reinforcement learning;Games;Tools;Real-time systems;Artificial intelligence},
doi={10.1109/VIS49827.2021.9623268},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623285,
author={Guo, Grace and Glenski, Maria and Shaw, ZhuanYi and Saldanha, Emily and Endert, Alex and Volkova, Svitlana and Arendt, Dustin},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={VAINE: Visualization and AI for Natural Experiments},
year={2021},
volume={},
number={},
pages={21-25},
abstract={Natural experiments are observational studies where the assignment of treatment conditions to different populations occurs by chance“in the wild”. Researchers from fields such as economics, healthcare, and the social sciences leverage natural experiments to conduct hypothesis testing and causal effect estimation for treatment and outcome variables that would otherwise be costly, infeasible, or unethical. In this paper, we introduce VAINE (Visualization and AI for Natural Experiments), a visual analytics tool for identifying and understanding natural experiments from observational data. We then demonstrate how VAINE can be used to validate causal relationships, estimate average treatment effects, and identify statistical phenomena such as Simpson’s paradox through two usage scenarios.},
keywords={Economics;Visual analytics;Sociology;Data visualization;Estimation;Medical services;Tools;Human-centered computing;Visualization;Visualization systems and tools;Visualization application domains;Visual analytics},
doi={10.1109/VIS49827.2021.9623285},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623322,
author={Bian, Yali and North, Chris and Krokos, Eric and Joseph, Sarah},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Semantic Explanation of Interactive Dimensionality Reduction},
year={2021},
volume={},
number={},
pages={26-30},
abstract={Interactive dimensionality reduction helps analysts explore the high-dimensional data based on their personal needs and domain-specific problems. Recently, expressive nonlinear models are employed to support these tasks. However, the interpretation of these human-steered nonlinear models during human-in-the-loop analysis has not been explored. To address this problem, we present a new visual explanation design called semantic explanation. Semantic explanation visualizes model behaviors in a manner that is similar to users’ direct projection manipulations. This design conforms to the spatial analytic process and enables analysts better understand the updated model in response to their interactions. We propose a pipeline to empower interactive dimensionality reduction with semantic explanation using counterfactuals. Based on the pipeline, we implement a visual text analytics system with nonlinear dimensionality reduction powered by deep learning via the BERT model. We demonstrate the efficacy of semantic explanation with two case studies of academic article exploration and intelligence analysis.},
keywords={Dimensionality reduction;Deep learning;Analytical models;Visualization;Conferences;Semantics;Pipelines;Interactive Dimensionality Reduction;Projection Explanation;Counterfactual Explanation;Human-in-the-loop Analysis},
doi={10.1109/VIS49827.2021.9623322},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623271,
author={Gomez, Oscar and Holter, Steffen and Yuan, Jun and Bertini, Enrico},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={AdViCE: Aggregated Visual Counterfactual Explanations for Machine Learning Model Validation},
year={2021},
volume={},
number={},
pages={31-35},
abstract={Rapid improvements in the performance of machine learning models have pushed them to the forefront of data-driven decision-making. Meanwhile, the increased integration of these models into various application domains has further highlighted the need for greater interpretability and transparency. To identify problems such as bias, overfitting, and incorrect correlations, data scientists require tools that explain the mechanisms with which these model decisions are made. In this paper we introduce AdViCE, a visual analytics tool that aims to guide users in black-box model debugging and validation. The solution rests on two main visual user interface innovations: (1) an interactive visualization design that enables the comparison of decisions on user-defined data subsets; (2) an algorithm and visual design to compute and visualize counterfactual explanations - explanations that depict model outcomes when data features are perturbed from their original values. We provide a demonstration of the tool through a use case that showcases the capabilities and potential limitations of the proposed approach.},
keywords={Technological innovation;Machine learning algorithms;Computational modeling;Visual analytics;Decision making;Data visualization;Machine learning;Machine learning;interpretability;explainability;counterfactual explanations;data visualization},
doi={10.1109/VIS49827.2021.9623271},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623289,
author={Olson, Matthew L. and Nguyen, Thuy-Vy and Dixit, Gaurav and Ratzlaff, Neale and Wong, Weng-Keen and Kahng, Minsuk},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Contrastive Identification of Covariate Shift in Image Data},
year={2021},
volume={},
number={},
pages={36-40},
abstract={Identifying covariate shift is crucial for making machine learning systems robust in the real world and for detecting training data biases that are not reflected in test data. However, detecting covariate shift is challenging, especially when the data consists of high-dimensional images, and when multiple types of localized covariate shift affect different subspaces of the data. Although automated techniques can be used to detect the existence of covariate shift, our goal is to help human users characterize the extent of covariate shift in large image datasets with interfaces that seamlessly integrate information obtained from the detection algorithms. In this paper, we design and evaluate a new visual interface that facilitates the comparison of the local distributions of training and test data. We conduct a quantitative user study on multi-attribute facial data to compare two different learned low-dimensional latent representations (pretrained ImageNet CNN vs. density ratio) and two user analytic workflows (nearest-neighbor vs. cluster-to-cluster). Our results indicate that the latent representation of our density ratio model, combined with a nearest-neighbor comparison, is the most effective at helping humans identify covariate shift.},
keywords={Training;Visualization;Conferences;Training data;Data visualization;Machine learning;Detection algorithms},
doi={10.1109/VIS49827.2021.9623289},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623320,
author={Oppermann, Michael and Liu, Luce and Munzner, Tamara},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={TimeElide: Visual Analysis of Non-Contiguous Time Series Slices},
year={2021},
volume={},
number={},
pages={41-45},
abstract={We introduce the design and implementation of TimeElide, a visual analysis tool for the novel data abstraction of non-contiguous time series slices, namely time intervals that contain a sequence of time-value pairs but are not adjacent to each other. This abstraction is relevant for analysis tasks where time periods of interest are known in advance or inferred from the data, rather than discovered through open-ended visual exploration. We present a visual encoding design space as an underpinning of TimeElide, and the new sparkbox technique for visualizing fine and coarse grained temporal structures within one view. Datasets from different domains and with varying characteristics guided the development and their analysis provides preliminary evidence of TimeElide’s utility. We provide open-source code and demo at https://github.com/UBC-InfoVis/time-elide and supplemental materials at https://osf.io/yqvmf/.},
keywords={Visualization;Codes;Conferences;Time series analysis;Data visualization;Tools;Encoding;Human-centered computing;Visualization;Visualization systems and tools},
doi={10.1109/VIS49827.2021.9623320},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623306,
author={Setlur, Vidya and Chung, Haeyong},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Semantic Resizing of Charts Through Generalization: A Case Study with Line Charts},
year={2021},
volume={},
number={},
pages={1-5},
abstract={Inspired by cartographic generalization principles, we present a generalization technique for rendering line charts at different sizes, preserving the important semantics of the data at that display size. The algorithm automatically determines the generalization operators to be applied at that size based on spatial density, distance, and the semantic importance of the various visualization elements in the line chart. A qualitative evaluation of the prototype that implemented the algorithm indicates that the generalized line charts preserved the general data shape, while minimizing visual clutter. We identify future opportunities where generalization can be extended and applied to other chart types and visual analysis authoring tools.},
keywords={Measurement;Visualization;Shape;Conferences;Semantics;Prototypes;Data visualization;Responsive charts;visual clutter;spatial metrics;Human-centered computing;Visualization},
doi={10.1109/VIS49827.2021.9623306},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623282,
author={Arunkumar, Anjana and Ginjpalli, Shashank and Bryan, Chris},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Bayesian Modelling of Alluvial Diagram Complexity},
year={2021},
volume={},
number={},
pages={51-55},
abstract={Alluvial diagrams are a popular technique for visualizing flow and relational data. However, successfully reading and interpreting the data shown in an alluvial diagram is likely influenced by factors such as data volume, complexity, and chart layout. To understand how alluvial diagram consumption is impacted by its visual features, we conduct two crowdsourced user studies with a set of alluvial diagrams of varying complexity, and examine (i) participant performance on analysis tasks, and (ii) the perceived complexity of the charts. Using the study results, we employ Bayesian modelling to predict participant classification of diagram complexity. We find that, while multiple visual features are important in contributing to alluvial diagram complexity, interestingly the importance of features seems to depend on the type of complexity being modeled, i.e. task complexity vs. perceived complexity.},
keywords={Visualization;Analytical models;Conferences;Computational modeling;Layout;Data visualization;Predictive models;Human-centered computing;Visualization;Visualization techniques;Empirical studies in visualization},
doi={10.1109/VIS49827.2021.9623282},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623314,
author={Ahmad, Jarryullah and Huynh, Elaine and Chevalier, Fanny},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={When Red Means Good, Bad, or Canada: Exploring People’s Reasoning for Choosing Color Palettes},
year={2021},
volume={},
number={},
pages={56-60},
abstract={Color palette selection is an essential aspect of visualization design, influencing data interpretation and evoking emotions in the viewer. Rules of thumb grounded in perceptual science and visual arts generally form the basis of recommendation tools to support color assignment, but palette design is more nuanced than optimizing for perceptual tasks. In this work, we investigate how the general public reconciles the varied facets of color design in visualization. Does their decision-making align with established rules of thumb? What factors do they take into consideration? Through a crowd-sourced study with 63 participants, we find that the majority of palette choices are perceptually motivated, but other factors such as semantic associations and bias also play a role. We identify some flaws in participant reasoning, highlight clashes in opinions, and present some implications for future work in this space.},
keywords={Fault diagnosis;Visualization;Image color analysis;Conferences;Decision making;Semantics;Data visualization;Color;General Public;Human Subjects Qualitative Studies},
doi={10.1109/VIS49827.2021.9623314},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623326,
author={Grossmann, Nicolas and Bernard, Jürgen and Sedlmair, Michael and Waldner, Manuela},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Does the Layout Really Matter? A Study on Visual Model Accuracy Estimation},
year={2021},
volume={},
number={},
pages={61-65},
abstract={In visual interactive labeling, users iteratively assign labels to data items until the machine model reaches an acceptable accuracy. A crucial step of this process is to inspect the model’s accuracy and decide whether it is necessary to label additional elements. In scenarios with no or very little labeled data, visual inspection of the predictions is required. Similarity-preserving scatterplots created through a dimensionality reduction algorithm are a common visualization that is used in these cases. Previous studies investigated the effects of layout and image complexity on tasks like labeling. However, model evaluation has not been studied systematically. We present the results of an experiment studying the influence of image complexity and visual grouping of images on model accuracy estimation. We found that users outperform traditional automated approaches when estimating a model’s accuracy. Furthermore, while the complexity of images impacts the overall performance, the layout of the items in the plot has little to no effect on estimations.},
keywords={Visualization;Layout;Estimation;Inspection;Predictive models;Prediction algorithms;Complexity theory;Human-centered computing;Visualization;Empirical studies in visualization Human-centered computing;Visualization design and evaluation methods},
doi={10.1109/VIS49827.2021.9623326},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623301,
author={Sahann, Raphael and Müller, Torsten and Schmidt, Johanna},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Histogram binning revisited with a focus on human perception},
year={2021},
volume={},
number={},
pages={66-70},
abstract={This paper presents a quantitative user study to evaluate how well users can visually perceive the underlying data distribution from a histogram representation. We used different sample and bin sizes and four different distributions (uniform, normal, bimodal, and gamma). The study results confirm that, in general, more bins correlate with fewer errors by the viewers. However, upon a certain number of bins, the error rate cannot be improved by adding more bins. By comparing our study results with the outcomes of existing mathematical models for histogram binning (e.g., Sturges’ formula, Scott’s normal reference rule, the Rice Rule, or Freedman–Diaconis’ choice), we can see that most of them overestimate the number of bins necessary to make the distribution visible to a human viewer.},
keywords={Histograms;Error analysis;Conferences;Mathematical models;empirical studies in visualization;histogram binning},
doi={10.1109/VIS49827.2021.9623301},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623273,
author={Boger, Tal and Most, Steven B. and Franconeri, Steven L.},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Jurassic Mark: Inattentional Blindness for a Datasaurus Reveals that Visualizations are Explored, not Seen},
year={2021},
volume={},
number={},
pages={71-75},
abstract={Graphs effectively communicate data because they capitalize on the visual system’s ability to rapidly extract patterns. Yet, this pattern extraction does not occur in a single glance. Instead, research on visual attention suggests that the visual system iteratively applies a sequence of filtering operations on an image, extracting patterns from subsets of visual information over time, while selectively inhibiting other information at each of these moments. To demonstrate that this powerful series of filtering operations also occurs during the perception of visualized data, we designed a task where participants made judgments from one class of marks on a scatterplot, presumably incentivizing them to relatively ignore other classes of marks. Participants consistently missed a conspicuous dinosaur in the ignored collection of marks (93% for a 1s presentation, and 61% for 2.5s), but not in a control condition where the incentive to ignore that collection was removed (25% for a 1s presentation, and 11% for 2.5s), revealing that data visualizations are not “seen” in a single glance, and instead require an active process of exploration.},
keywords={Dinosaurs;Visualization;Filtration;Data visualization;Process control;Blindness;Visual systems;perception & cognition;attention;communcation/presentation},
doi={10.1109/VIS49827.2021.9623273},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623297,
author={Parsons, Paul and Shukla, Prakash and Park, Chorong},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Fixation and Creativity in Data Visualization Design: Experiences and Perspectives of Practitioners},
year={2021},
volume={},
number={},
pages={76-80},
abstract={Data visualization design often requires creativity, and research is needed to understand its nature and means for promoting it. The current visualization literature on creativity is not well developed, especially with respect to the experiences of professional data visualization designers. We conducted semi-structured interviews with 15 data visualization practitioners, focusing on a specific aspect of creativity known as design fixation. Fixation occurs when designers adhere blindly or prematurely to a set of ideas that limit creative outcomes. We present practitioners’ experiences and perspectives from their own design practice, specifically focusing on their views of (i) the nature of fixation, (ii) factors encouraging fixation, and (iii) factors discouraging fixation. We identify opportunities for future research related to chart recommendations, inspiration, and perspective shifts in data visualization design.},
keywords={Conferences;Data visualization;Focusing;Interviews;Creativity;Human-centered computing;Visualization},
doi={10.1109/VIS49827.2021.9623297},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623305,
author={Fischer, Maximilian T. and Frings, Alexander and Keim, Daniel A. and Seebacher, Daniel},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Towards a Survey on Static and Dynamic Hypergraph Visualizations},
year={2021},
volume={},
number={},
pages={81-85},
abstract={Leveraging hypergraph structures to model advanced processes has gained much attention over the last few years in many areas, ranging from protein-interaction in computational biology to image retrieval using machine learning. Hypergraph models can provide a more accurate representation of the underlying processes while reducing the overall number of links compared to regular representations. However, interactive visualization methods for hypergraphs and hypergraph-based models have rarely been explored or systematically analyzed. This paper reviews the existing research landscape for hypergraph and hypergraph model visualizations and assesses the currently employed techniques. We provide an overview and a categorization of proposed approaches, focusing on performance, scalability, interaction support, successful evaluation, and the ability to represent different underlying data structures, including a recent demand for a temporal representation of interaction networks and their improvements beyond graph-based methods. Lastly, we discuss the strengths and weaknesses of the approaches and give an insight into the future challenges arising in this emerging research field.},
keywords={Proteins;Analytical models;Visualization;Computational modeling;Biological system modeling;Scalability;Image retrieval;Hypergraphs;hypergraph model;temporal;visualization;visual analytics;survey},
doi={10.1109/VIS49827.2021.9623305},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623286,
author={Lohfink, Anna-Pia and Gartzky, Frederike and Wetzels, Florian and Vollmer, Luisa and Garth, Christoph},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Time-Varying Fuzzy Contour Trees},
year={2021},
volume={},
number={},
pages={86-90},
abstract={We present a holistic, topology-based visualization technique for spatial time series data based on an adaptation of Fuzzy Contour Trees. Common analysis approaches for time dependent scalar fields identify and track specific features. To give a more general overview of the data, we extend Fuzzy Contour Trees, from the visualization and simultaneous analysis of the topology of multiple scalar fields, to time dependent scalar fields. The resulting time-varying Fuzzy Contour Trees allow the comparison of multiple time steps that are not required to be consecutive. We provide specific interaction and navigation possibilities that allow the exploration of individual time steps and time windows in addition to the behavior of the contour trees over all time steps. To achieve this, we reduce an existing alignment to multiple sub-alignments and adapt the Fuzzy Contour Tree-layout to continuously reflect changes and similarities in the sub-alignments. We apply time-varying Fuzzy Contour Trees to different real-world data sets and demonstrate their usefulness.},
keywords={Navigation;Design methodology;Conferences;Time series analysis;Data visualization;Spatial databases;Topology;Human-centered computing;Visualization;Visualization techniques;Treemaps;Visualization design and evaluation methods},
doi={10.1109/VIS49827.2021.9623286},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623298,
author={Şahıstan, Alper and Demirci, Serkan and Morrical, Nathan and Zellmann, Stefan and Aman, Aytek and Wald, Ingo and Güdükbay, Uğur},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Ray-traced Shell Traversal of Tetrahedral Meshes for Direct Volume Visualization},
year={2021},
volume={},
number={},
pages={91-95},
abstract={A well-known method for rendering unstructured volumetric data is tetrahedral marching (tet marching), where rays are marched through a series of tetrahedral elements. Rowever, existing tet marching techniques do not easily generalize to rays with arbitrary origin and direction required for advanced shading effects or non-convex meshes. Additionally, the memory footprint of these methods may exceed GPU memory limits. Interactive performance and high image quality are opposing goals. Our approach significantly lowers the burden to render unstructured datasets with high image fidelity while maintaining real-time and interactive performance even for large datasets. To this end, we leverage hardware-accelerated ray tracing to find entry and exit faces for a given ray into a volume and utilize a compact mesh representation to enable the efficient marching of arbitrary rays, thus allowing for advanced shading effects that ultimately yields more convincing and grounded images. Our approach is also robust, supporting both convex and non-convex unstructured meshes. We show that our method achieves interactive rates even with moderately-sized datasets while secondary effects are applied.},
keywords={Image quality;Conferences;Graphics processing units;Ray tracing;Rendering (computer graphics);Real-time systems;Faces;Human-centered computing;Visualization;Visualization application domains;Scientific visualization;Computing methodologies;Computer Graphics;Rendering;Ray Tracing},
doi={10.1109/VIS49827.2021.9623298},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623300,
author={Sharma, Mohit and Masood, Talha Bin and Thygesen, Signe S. and Linares, Mathieu and Hotz, Ingrid and Natarajan, Vijay},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Segmentation Driven Peeling for Visual Analysis of Electronic Transitions},
year={2021},
volume={},
number={},
pages={96-100},
abstract={Electronic transitions in molecules due to absorption or emission of light is a complex quantum mechanical process. Their study plays an important role in the design of novel materials. A common yet challenging task in the study is to determine the nature of those electronic transitions, i.e. which subgroups of the molecule are involved in the transition by donating or accepting electrons, followed by an investigation of the variation in the donor-acceptor behavior for different transitions or conformations of the molecules. In this paper, we present a novel approach towards the study of electronic transitions based on the visual analysis of a bivariate field, namely the electron density in the hole and particle Natural Transition Orbital (NTO). The visual analysis focuses on the continuous scatter plots (CSPs) of the bivariate field linked to their spatial domain. The method supports selections in the CSP visualized as fiber surfaces in the spatial domain, the grouping of atoms, and segmentation of the density fields to peel the CSP. This peeling operator is central to the visual analysis process and helps identify donors and acceptors. We study different molecular systems, identifying local excitation and charge transfer excitations to demonstrate the utility of the method.},
keywords={Visualization;Data analysis;Absorption;Conferences;Data visualization;Quantum mechanics;Orbits;Human-centered computing;Visualization;Visualization application domains;Scientific visualization},
doi={10.1109/VIS49827.2021.9623300},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623310,
author={Guo, Hanqi and Peterka, Tom},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Exact Analytical Parallel Vectors},
year={2021},
volume={},
number={},
pages={101-105},
abstract={This paper demonstrates that parallel vector curves are piecewise cubic rational curves in 3D piecewise linear vector fields. Parallel vector curves—loci of points where two vector fields are parallel— have been widely used to extract features including ridges, valleys, and vortex core lines in scientific data. We define the term generalized and underdetermined eigensystem in the form of Ax + a = $\lambda$(Bx + b) in order to derive the piecewise rational representation of 3D parallel vector curves. We discuss how singularities of the rationals lead to different types of intersections with tetrahedral cells.},
keywords={Three-dimensional displays;Conferences;Distributed databases;Data visualization;Reconstruction algorithms;Parallel processing;Filtering algorithms},
doi={10.1109/VIS49827.2021.9623310},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623267,
author={Athawale, Tushar M. and Sane, Sudhanshu and Johnson, Chris R.},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Uncertainty Visualization of the Marching Squares and Marching Cubes Topology Cases},
year={2021},
volume={},
number={},
pages={106-110},
abstract={Marching squares (MS) and marching cubes (MC) are widely used algorithms for level-set visualization of scientific data. In this paper, we address the challenge of uncertainty visualization of the topology cases of the MS and MC algorithms for uncertain scalar field data sampled on a uniform grid. The visualization of the MS and MC topology cases for uncertain data is challenging due to their exponential nature and the possibility of multiple topology cases per cell of a grid. We propose the topology case count and entropy-based techniques for quantifying uncertainty in the topology cases of the MS and MC algorithms when noise in data is modeled with probability distributions. We demonstrate the applicability of our techniques for independent and correlated uncertainty assumptions. We visualize the quantified topological uncertainty via color mapping proportional to uncertainty, as well as with interactive probability queries in the MS case and entropy isosurfaces in the MC case. We demonstrate the utility of our uncertainty quantification framework in identifying the isovalues exhibiting relatively high topological uncertainty. We illustrate the effectiveness of our techniques via results on synthetic, simulation, and hixel datasets.},
keywords={Uncertainty;Image color analysis;Conferences;Computational modeling;Probability distribution;Entropy;Data models;Human-centered computing;Visualization;Visualization application domains;Scientific visualization},
doi={10.1109/VIS49827.2021.9623267},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623307,
author={Ruan, Shaolun and Wang, Yong and Guan, Qiang},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Intercept Graph: An Interactive Radial Visualization for Comparison of State Changes},
year={2021},
volume={},
number={},
pages={111-115},
abstract={State change comparison of multiple data items is often necessary in multiple application domains, such as medical science, financial engineering, sociology, biological science, etc. Slope graphs and grouped bar charts have been widely used to show a “before-and-after” story of different data states and indicate their changes. However, they visualize state changes as either slope or difference of bars, which has been proved less effective for quantitative comparison. Also, both visual designs suffer from visual clutter issues with an increasing number of data items. In this paper, we propose Intercept Graph, a novel visual design to facilitate effective interactive comparison of state changes. Specifically, a radial design is proposed to visualize the starting and ending states of each data item and the line segment length explicitly encodes the “state change By interactively adjusting the radius of the inner circular axis, Intercept Graph can smoothly filter the large state changes and magnify the difference between similar state changes, mitigating the visual clutter issues and enhancing the effective comparison of state changes. We conducted a case study through comparing Intercept Graph with slope graphs and grouped bar charts on real datasets to demonstrate the effectiveness of Intercept Graph.},
keywords={Visualization;Conferences;Sociology;Data visualization;Focusing;Tools;Clutter;Visual representation design;Interaction;State change comparison;Radial visualization},
doi={10.1109/VIS49827.2021.9623307},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623319,
author={Fisher, Jacob and Chang, Remco and Wu, Eugene},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Automatic Y-axis Rescaling in Dynamic Visualizations},
year={2021},
volume={},
number={},
pages={116-120},
abstract={Animated and interactive data visualizations dynamically change the data rendered in a visualization (e.g., bar chart). As the data changes, the y-axis may need to be rescaled as the domain of the data changes. Each axis rescaling potentially improves the readability of the current chart, but may also disorient the user. In contrast to static visualizations, where there is considerable literature to help choose the appropriate y-axis scale, there is a lack of guidance about how and when rescaling should be used in dynamic visualizations. Existing visualization systems and libraries adapt a fixed global y-axis, or rescale every time the data changes. Yet, professional visualizations, such as in data journalism, do not adopt either strategy. They instead carefully and manually choose when to rescale based on the analysis task and data. To this end, we conduct a series of Mechanical Turk experiments to study the potential of dynamic axis rescaling and the factors that affect its effectiveness. We find that the appropriate rescaling policy is both task- and data-dependent, and we do not find one clear policy choice for all situations.},
keywords={Conferences;Data visualization;Journalism;Libraries;Task analysis;Bars;Human-centered computing;Visualization;Empirical studies in visualization; Human-centered computing;Visualization theory, concepts and paradigms},
doi={10.1109/VIS49827.2021.9623319},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623318,
author={Husain, Fahd and Proulx, Pascale and Chang, Meng-Wei and Romero-Gómez, Rosa and Vasquez, Holland},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={A Mixed-Initiative Visual Analytics Approach for Qualitative Causal Modeling},
year={2021},
volume={},
number={},
pages={121-125},
abstract={Modeling complex systems is a time-consuming, difficult and fragmented task, often requiring the analyst to work with disparate data, a variety of models, and expert knowledge across a diverse set of domains. Applying a user-centered design process, we developed a mixed-initiative visual analytics approach, a subset of the Causemos platform, that allows analysts to rapidly assemble qualitative causal models of complex socio-natural systems. Our approach facilitates the construction, exploration, and curation of qualitative models bringing together data across disparate domains. Referencing a recent user evaluation, we demonstrate our approach’s ability to interactively enrich user mental models and accelerate qualitative model building.},
keywords={Analytical models;Computational modeling;Visual analytics;Conferences;User centered design;Data visualization;Data models;Human-centered computing;Visualization;Visualization techniques;Treemaps;Visualization design and evaluation methods},
doi={10.1109/VIS49827.2021.9623318},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623272,
author={Li, Yiran and Musabandesu, Erin and Fujiwara, Takanori and Loge, Frank J. and Ma, Kwan-Liu},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={A Visual Analytics System for Water Distribution System Optimization},
year={2021},
volume={},
number={},
pages={126-130},
abstract={The optimization of water distribution systems (WDSs) is vital to minimize energy costs required for their operations. A principal approach taken by researchers is identifying an optimal scheme for water pump controls through examining computational simulations of WDSs. However, due to a large number of possible control combinations and the complexity of WDS simulations, it remains non-trivial to identify the best pump controls by reviewing the simulation results. To address this problem, we design a visual analytics system that helps understand relationships between simulation inputs and outputs towards better optimization. Our system incorporates interpretable machine learning as well as multiple linked visualizations to capture essential input-output relationships from complex WDS simulations. We demonstrate our system’s effectiveness through a practical case study and evaluate its usability through expert reviews. Our results show that our system can lessen the burden of analysis and assist in determining optimal operating schemes.},
keywords={Costs;Visual analytics;Computational modeling;Simulation;Conferences;Machine learning;Water pumps},
doi={10.1109/VIS49827.2021.9623272},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623317,
author={Baidak, Bella and Hussain, Yahiya and Kelminson, Emma and Jones, Thouis R. and Franke, Loraine and Haehn, Daniel},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={CellProfiler Analyst Web (CPAW) - Exploration, analysis, and classification of biological images on the web},
year={2021},
volume={},
number={},
pages={131-135},
abstract={CellProfiler Analyst (CPA) has enabled the scientific research community to explore image-based data and classify complex biological phenotypes through an interactive user interface since its release in 2008. This paper describes CellProfiler Analyst Web (CPAW), a newly redesigned and web-based version of the software, allowing for greater accessibility, quicker setup, and facilitating a simple workflow for users. Installation and managing new versions has been challenging and time-consuming, historically. CPAW is an alternative that ensures installation and future updates are not a hassle to the user. CPAW ports the core iteration loop of CPA to a pure server-less browser environment using modern web-development technologies, allowing computationally heavy activities, like machine learning, to occur without freezing the user interface (UI). With a setup as simple as navigating to a website, CPAW presents a clean UI to the user to refine their classifier and explore pheno-typic data easily. We evaluated both the old and the new version of the software in an extensive domain expert study. We found that users could complete the essential classification tasks in CPAW and CPA 3.0 with the same efficiency. Additionally, users completed the tasks 20 percent faster using CPAW compared to CPA 3.0. The code of CellProfiler Analyst Web is open-source and available at https://mpsych.github.io/CellProfilerAnalystWeb/.},
keywords={Ports (computers);Codes;Navigation;Conferences;Machine learning;User interfaces;Browsers;Biological Images;Visualization;Machine Learning Classification;Evaluation Methods},
doi={10.1109/VIS49827.2021.9623317},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623312,
author={Liu, Qiangqiang and Li, Quan and Zhu, Zhihua and Ye, Tangzhi and Ma, Xiaojuan},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Inspecting the Process of Bank Credit Rating via Visual Analytics},
year={2021},
volume={},
number={},
pages={136-140},
abstract={Bank credit rating classifies banks into different levels based on publicly disclosed and internal information, serving as an important input in financial risk management. However, domain experts have a vague idea of exploring and comparing different bank credit rating schemes. A loose connection between subjective and quantitative analysis and difficulties in determining appropriate indicator weights obscure understanding of bank credit ratings. Furthermore, existing models fail to consider bank types by just applying a unified indicator weight set to all banks. We propose RatingVis to assist experts in exploring and comparing different bank credit rating schemes. It supports interactively inferring indicator weights for banks by involving domain knowledge and considers bank types in the analysis loop. We conduct a case study with real-world bank data to verify the efficacy of RatingVis. Expert feedback suggests that our approach helps them better understand different rating schemes.},
keywords={Statistical analysis;Visual analytics;Conferences;Data visualization;Risk management;Human-centered computing;Visualization},
doi={10.1109/VIS49827.2021.9623312},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623295,
author={Yaeli, Avi and Zeltyn, Sergey},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Where and Why is My Bot Failing? A Visual Analytics Approach for Investigating Failures in Chatbot Conversation Flows},
year={2021},
volume={},
number={},
pages={141-145},
abstract={The ongoing coronavirus pandemic has accelerated the adoption of AI-powered task-oriented chatbots by businesses and healthcare organizations. Despite advancements in chatbot platforms, implementing a successful and effective bot is still challenging and requires a lot of manual work. There is a strong need for tools to help conversation analysts quickly identify problem areas and, consequently, introduce changes to chatbot design. We present a visual analytics approach and tool for conversation analysts to identify and assess common patterns of failure in conversation flows. We focus on two key capabilities: path flow analysis and root cause analysis. Interim evaluation results from applying our tool in real-world customer production projects are presented.},
keywords={Root cause analysis;Pandemics;Visual analytics;Production;Organizations;Medical services;Manuals;visual analytics;conversation analytics;visualization systems and tools;chatbots;dialogue systems;root cause analysis},
doi={10.1109/VIS49827.2021.9623295},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623287,
author={Mathews, Noble Saji and Chimalakonda, Sridhar and Jain, Suresh},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={AiR: An Augmented Reality Application for Visualizing Air Pollution},
year={2021},
volume={},
number={},
pages={146-150},
abstract={In order to effectively combat Air Pollution, it is necessary for the government and the community to work together. Easily comprehensible visualizations can play a major role in drawing public attention and spreading awareness about seemingly intangible air pollution. Considering the widespread usage of Android-based devices, in this paper, we propose an Augmented Reality based application called AiR, to help users to visualize pollutants in the air and to create an immersive user experience. It aims to interactively engage a wide variety of users and create awareness without overwhelming them with data. AiR visualizes 12 pollutants $[PM _{10}$, $PM _{2.5}$, NO, NO2, $NO _{x}$, CO, SO2, O3, NH3, C6 H6, (CH3)C6 H5 and (CH3)2 C6 H5] through unique models. We demonstrate our application on pollution data by CPCB from various weather stations across India collected over the initial lockdown period due to COVID-19 in India.},
keywords={Conferences;Urban areas;Government;Data visualization;Air pollution;User experience;Mobile applications;Human-centered computing;Visualization;Visualization systems and tools;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality;Applied computing;Physical sciences and engineering;Earth and atmospheric sciences},
doi={10.1109/VIS49827.2021.9623287},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623269,
author={Li, Raymond and Hoque, Enamul and Carenini, Giuseppe and Lester, Richard and Chau, Raymond},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={ConVIScope: Visual Analytics for Exploring Patient Conversations},
year={2021},
volume={},
number={},
pages={151-155},
abstract={The proliferation of text messaging for mobile health is generating a large amount of patient-doctor conversations that can be extremely valuable to health care professionals. We present ConVIScope, a visual text analytic system that tightly integrates interactive visualization with natural language processing in analyzing patient-doctor conversations. ConVIScope was developed in collaboration with healthcare professionals following a user-centered iterative design. Case studies with six domain experts suggest the potential utility of ConVIScope and reveal lessons for further developments.},
keywords={Visual analytics;Design methodology;Conferences;Collaboration;Medical services;Natural language processing;Electronic messaging;Human-centered computing;Visualization;Visualization design and evaluation methods},
doi={10.1109/VIS49827.2021.9623269},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623313,
author={Latif, Shahid and Agarwal, Shivam and Gottschalk, Simon and Chrosch, Carina and Feit, Felix and Jahn, Johannes and Braun, Tobias and Tchenko, Yanick Christian and Demidova, Elena and Beck, Fabian},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Visually Connecting Historical Figures Through Event Knowledge Graphs},
year={2021},
volume={},
number={},
pages={156-160},
abstract={Knowledge graphs store information about historical figures and their relationships indirectly through shared events. We developed a visualization system, VisKonnect, for analyzing the intertwined lives of historical figures based on the events they participated in. A user’s query is parsed for identifying named entities, and related data is retrieved from an event knowledge graph. While a short textual answer to the query is generated using the GPT-3 language model, various linked visualizations provide context, display additional information related to the query, and allow exploration.},
keywords={Conferences;Natural languages;Data visualization;Context modeling;Knowledge graphs;general public;question answering;visualization;natural language generation},
doi={10.1109/VIS49827.2021.9623313},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623328,
author={Song, Hayeong and Fu, Yu and Saket, Bahador and Stasko, John},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Understanding the Effects of Visualizing Missing Values on Visual Data Exploration},
year={2021},
volume={},
number={},
pages={161-165},
abstract={When performing data analysis, people often confront data sets containing missing values. We conducted an empirical study to understand the effect of visualizing those missing values on participants’ decision-making processes while performing a visual data exploration task. More specifically, our study participants purchased a hypothetical portfolio of stocks based on a data set where some stocks had missing values for attributes such as PE ratio, beta, and EPS. The experiment used scatterplots to communicate the stock data. For one group of participants, stocks with missing values simply were not shown, while the second group saw such stocks depicted with estimated values as points with error bars. We measured participants’ cognitive load involved in decision-making with data with missing values. Our results indicate that their decision-making workflow was different across two conditions.},
keywords={Visualization;Data analysis;Atmospheric measurements;Conferences;Decision making;Data visualization;Particle measurements;Human-centered computing;Visualization;Empiriacal evaluation;Missing data},
doi={10.1109/VIS49827.2021.9623328},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623324,
author={Setlur, Vidya and Battersby, Sarah and Wong, Tracy},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={GeoSneakPique: Visual Autocompletion for Geospatial Queries},
year={2021},
volume={},
number={},
pages={166-170},
abstract={How many crimes occurred in the city center? And exactly which part of town is the “city center”? While location is at the heart of many data questions, geographic location can be difficult to specify in natural language (NL) queries. This is especially true when working with fuzzy cognitive regions or regions that may be defined based on data distributions instead of absolute administrative location (e.g., state, country). GeoSneakPique presents a novel method for using a mapping widget to support the NL query process, allowing users to specify location via direct manipulation with data-driven guidance on spatial distributions to help select the area of interest. Users receive feedback to help them evaluate and refine their spatial selection interactively and can save spatial definitions for re-use in subsequent queries. We conduct a qualitative evaluation of the GeoSneakPique that indicates the usefulness of the interface as well as opportunities for better supporting geospatial workflows in visual analysis tasks employing cognitive regions.},
keywords={Measurement;Heart;Visualization;Graphical models;Image color analysis;Query processing;Urban areas;Data-driven scaffolds;cognitive region;Human-centered computing;Visualization},
doi={10.1109/VIS49827.2021.9623324},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623315,
author={Liu, Zhicheng and Chen, Chen and Morales, Francisco and Zhao, Yishan},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Atlas: Grammar-based Procedural Generation of Data Visualizations},
year={2021},
volume={},
number={},
pages={171-175},
abstract={We present Atlas, a procedural grammar for constructing data visualizations. Unlike most visualization grammars which use declarative specifications to describe visualization components, Atlas exposes the generative process of a visualization through a set of concatenated high-level production rules. Each of these rules describes how an input graphical object is created, transformed, or joined with abstract data to derive an output object. The visualization state can thus be inspected throughout the generative process. We demonstrate Atlas’ expressivity through a catalog of visualization designs, and discuss the trade-offs in its design by comparing it to state-of-the-art grammars.},
keywords={Conferences;Data visualization;Production;Grammar;Human-centered computing;Visualization;Visualization systems and tools;Visualization toolkits},
doi={10.1109/VIS49827.2021.9623315},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623294,
author={McNutt, Andrew},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={On the Potential of Zines as a Medium for Visualization},
year={2021},
volume={},
number={},
pages={176-180},
abstract={Zines are a form of small-circulation self-produced publication often akin to a magazine. This free-form medium has a long history and has been used as means for personal or intimate expression, as a way for marginalized people to describe issues that are important to them, and as a venue for graphical experimentation. It would seem then that zines would make an ideal vehicle for the recent interest in applying feminist or humanist ideas to visualization. Yet, there has been little work combining visualization and zines. In this paper we explore the potential of this intersection by analyzing examples of zines that use data graphics and by describing the pedagogical value that they can have in a visualization classroom. In doing so, we argue that there are plentiful opportunities for visualization research and practice in this rich intersectional-medium.},
keywords={Graphics;Conferences;Data visualization;History;Gender issues;Human-centered computing;Visualization;Visualization application domains},
doi={10.1109/VIS49827.2021.9623294},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623296,
author={Norambuena, Brian Felipe Keith and Mitra, Tanushree and North, Chris},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Narrative Sensemaking: Strategies for Narrative Maps Construction},
year={2021},
volume={},
number={},
pages={181-185},
abstract={Narrative sensemaking is a fundamental process to understand sequential information. Narrative maps are a visual representation framework that can aid analysts in this process. They allow analysts to understand the big picture of a narrative, uncover new relationships between events, and model connections between storylines. As a sensemaking tool, narrative maps have applications in intelligence analysis, misinformation modeling, and computational journalism. In this work, we seek to understand how analysts construct narrative maps in order to improve narrative map representation and extraction methods. We perform an experiment with a data set of news articles. Our main contribution is an analysis of how analysts construct narrative maps. The insights extracted from our study can be used to design narrative map visualizations, extraction algorithms, and visual analytics tools to support the sensemaking process.},
keywords={Training;Analytical models;Design methodology;Computational modeling;Visual analytics;Layout;Data visualization;Human-centered computing;Visualization;Empirical studies in visualization;Human-centered Visualization;Visualization techniques;Graph drawings},
doi={10.1109/VIS49827.2021.9623296},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623264,
author={Sultanum, Nicole and Bezerianos, Anastasia and Chevalier, Fanny},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Text Visualization and Close Reading for Journalism with Storifier},
year={2021},
volume={},
number={},
pages={186-190},
abstract={Journalistic inquiry often requires analysis and close study of large text collections around a particular topic. We argue that this practice could benefit from a more text- and reading-centered approach to journalistic text analysis, one that allows for a fluid transition between overview of entities of interest, the context of these entities in the text, down to the detailed documents they are extracted from. In this context, we present the design and development of Storifier, a text visualization tool created in close collaboration with a large francophone news office. We also discuss a case study on how our tool was used to analyze a text collection and helped publish a story.},
keywords={Visualization;Fluids;Text analysis;Conferences;Collaboration;Tools;Journalism},
doi={10.1109/VIS49827.2021.9623264},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623288,
author={Vaidya, Sahaj and Cai, Jie and Basu, Soumyadeep and Naderi, Azadeh and Wohn, Donghee Yvette and Dasgupta, Aritra},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Conceptualizing Visual Analytic Interventions for Content Moderation},
year={2021},
volume={},
number={},
pages={191-195},
abstract={Modern social media platforms like Twitch, YouTube, etc., embody an open space for content creation and consumption. However, an unintended consequence of such content democratization is the proliferation of toxicity and abuse that content creators get subjected to. Commercial and volunteer content moderators play an indispensable role in identifying bad actors and minimizing the scale and degree of harmful content. Moderation tasks are often laborious, complex, and even if semi-automated, they involve high-consequence human decisions that affect the safety and popular perception of the platforms. In this paper, through an interdisciplinary collaboration among researchers from social science, human-computer interaction, and visualization, we present a systematic understanding of how visual analytics can help in human-in-the-loop content moderation. We contribute a characterization of the data-driven problems and needs for proactive moderation and present a mapping between the needs and visual analytic tasks through a task abstraction framework. We discuss how the task abstraction framework can be used for transparent moderation, design interventions for moderators’ well-being, and ultimately, for creating futuristic human-machine interfaces for data-driven content moderation.},
keywords={Human computer interaction;Toxicology;Systematics;Social networking (online);Visual analytics;Social sciences;Decision making;Content Moderation;Social Media;Task Abstractions;Real-time Decision-Making},
doi={10.1109/VIS49827.2021.9623288},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623299,
author={Bhargava, Rahul and Williams, Dee and D’Ignazio, Catherine},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={How Learners Sketch Data Stories},
year={2021},
volume={},
number={},
pages={196-200},
abstract={Learning data storytelling involves a complex web of skills. Professional and academic educational offerings typically focus on the computational literacies required, but professionals in the field employ many non-technical methods; sketching by hand on paper is a common practice. This paper introduces and classifies a corpus of 101 data sketches produced by participants as part of a guided learning activity in informal and formal settings. We manually code each sketch against 12 metrics related to visual encodings, representations, and story structure. We find evidence for preferential use of positional and shape-based encodings, frequent use of symbolic and textual representations, and a high prevalence of stories comparing subsets of data. These findings contribute to our understanding of how learners sketch with data. This case study can inform tool design for learners, and help create educational programs that introduce novices to sketching practices used by experts.},
keywords={Measurement;Human computer interaction;Visualization;Educational programs;Codes;Design methodology;Conferences;Human-centered computing Visualization design and evaluation methods;Social and professional topics Informal education},
doi={10.1109/VIS49827.2021.9623299},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623291,
author={Kim, Younghoon and Heer, Jeffrey},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Gemini2: Generating Keyframe-Oriented Animated Transitions Between Statistical Graphics},
year={2021},
volume={},
number={},
pages={201-205},
abstract={Complex animated transitions may be easier to understand when divided into separate, consecutive stages. However, effective staging requires careful attention to both animation semantics and timing parameters. We present Gemini2, a system for creating staged animations from a sequence of chart keyframes. Given only a start state and an end state, Gemini2 can automatically recommend intermediate keyframes for designers to consider. The Gemini2 recommendation engine leverages Gemini, our prior work, and GraphScape to itemize the given complex change into semantic edit operations and to recombine operations into stages with a guided order for clearly conveying the semantics. To evaluate Gemini2’s recommendations, we conducted a human-subject study in which participants ranked recommended animations from both Gemini2 and Gemini. We find that Gemini2’s animation recommendation ranking is well aligned with subjects’ preferences, and Gemini2 can recommend favorable animations that Gemini cannot support.},
keywords={Visualization;Conferences;Semantics;User interfaces;Animation;Timing;Engines;H.5.2 [User Interfaces]: User Interfaces;Graphical user interfaces (GUI);H.5.m [Information Interfaces and Presentation]: Miscellaneous},
doi={10.1109/VIS49827.2021.9623291},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623311,
author={},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Author Index},
year={2021},
volume={},
number={},
pages={207-209},
abstract={Presents an index of the authors whose articles are published in the conference proceedings record.},
keywords={},
doi={10.1109/VIS49827.2021.9623311},
ISSN={},
month={Oct},}
