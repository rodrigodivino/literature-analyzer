@INPROCEEDINGS{9623268,
author={Tabatabai, Delyar and Ruangrotsakun, Anita and Irvine, Jed and Dodge, Jonathan and Shureih, Zeyad and Lam, Kin-Ho and Burnett, Margaret and Fern, Alan and Kahng, Minsuk},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={“Why did my AI agent lose?”: Visual Analytics for Scaling Up After-Action Review},
year={2021},
volume={},
number={},
pages={16-20},
abstract={How can we help domain-knowledgeable users who do not have expertise in AI analyze why an AI agent failed? Our research team previously developed a new structured process for such users to assess AI, called After-Action Review for AI (AAR/AI), consisting of a series of steps a human takes to assess an AI agent and formalize their understanding. In this paper, we investigate how the AAR/AI process can scale up to support reinforcement learning (RL) agents that operate in complex environments. We augment the AAR/AI process to be performed at three levels—episode-level, decision-level, and explanation-level—and integrate it into our redesigned visual analytics interface. We illustrate our approach through a usage scenario of analyzing why a RL agent lost in a complex real-time strategy game built with the StarCraft 2 engine. We believe integrating structured processes like AAR/AI into visualization tools can help visualization play a more critical role in AI interpretability.},
keywords={Visual analytics;Conferences;Reinforcement learning;Games;Tools;Real-time systems;Artificial intelligence},
doi={10.1109/VIS49827.2021.9623268},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623285,
author={Guo, Grace and Glenski, Maria and Shaw, ZhuanYi and Saldanha, Emily and Endert, Alex and Volkova, Svitlana and Arendt, Dustin},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={VAINE: Visualization and AI for Natural Experiments},
year={2021},
volume={},
number={},
pages={21-25},
abstract={Natural experiments are observational studies where the assignment of treatment conditions to different populations occurs by chance“in the wild”. Researchers from fields such as economics, healthcare, and the social sciences leverage natural experiments to conduct hypothesis testing and causal effect estimation for treatment and outcome variables that would otherwise be costly, infeasible, or unethical. In this paper, we introduce VAINE (Visualization and AI for Natural Experiments), a visual analytics tool for identifying and understanding natural experiments from observational data. We then demonstrate how VAINE can be used to validate causal relationships, estimate average treatment effects, and identify statistical phenomena such as Simpson’s paradox through two usage scenarios.},
keywords={Economics;Visual analytics;Sociology;Data visualization;Estimation;Medical services;Tools;Human-centered computing;Visualization;Visualization systems and tools;Visualization application domains;Visual analytics},
doi={10.1109/VIS49827.2021.9623285},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623322,
author={Bian, Yali and North, Chris and Krokos, Eric and Joseph, Sarah},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={Semantic Explanation of Interactive Dimensionality Reduction},
year={2021},
volume={},
number={},
pages={26-30},
abstract={Interactive dimensionality reduction helps analysts explore the high-dimensional data based on their personal needs and domain-specific problems. Recently, expressive nonlinear models are employed to support these tasks. However, the interpretation of these human-steered nonlinear models during human-in-the-loop analysis has not been explored. To address this problem, we present a new visual explanation design called semantic explanation. Semantic explanation visualizes model behaviors in a manner that is similar to users’ direct projection manipulations. This design conforms to the spatial analytic process and enables analysts better understand the updated model in response to their interactions. We propose a pipeline to empower interactive dimensionality reduction with semantic explanation using counterfactuals. Based on the pipeline, we implement a visual text analytics system with nonlinear dimensionality reduction powered by deep learning via the BERT model. We demonstrate the efficacy of semantic explanation with two case studies of academic article exploration and intelligence analysis.},
keywords={Dimensionality reduction;Deep learning;Analytical models;Visualization;Conferences;Semantics;Pipelines;Interactive Dimensionality Reduction;Projection Explanation;Counterfactual Explanation;Human-in-the-loop Analysis},
doi={10.1109/VIS49827.2021.9623322},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9623271,
author={Gomez, Oscar and Holter, Steffen and Yuan, Jun and Bertini, Enrico},
booktitle={2021 IEEE Visualization Conference (VIS)}, title={AdViCE: Aggregated Visual Counterfactual Explanations for Machine Learning Model Validation},
year={2021},
volume={},
number={},
pages={31-35},
abstract={Rapid improvements in the performance of machine learning models have pushed them to the forefront of data-driven decision-making. Meanwhile, the increased integration of these models into various application domains has further highlighted the need for greater interpretability and transparency. To identify problems such as bias, overfitting, and incorrect correlations, data scientists require tools that explain the mechanisms with which these model decisions are made. In this paper we introduce AdViCE, a visual analytics tool that aims to guide users in black-box model debugging and validation. The solution rests on two main visual user interface innovations: (1) an interactive visualization design that enables the comparison of decisions on user-defined data subsets; (2) an algorithm and visual design to compute and visualize counterfactual explanations - explanations that depict model outcomes when data features are perturbed from their original values. We provide a demonstration of the tool through a use case that showcases the capabilities and potential limitations of the proposed approach.},
keywords={Technological innovation;Machine learning algorithms;Computational modeling;Visual analytics;Decision making;Data visualization;Machine learning;Machine learning;interpretability;explainability;counterfactual explanations;data visualization},
doi={10.1109/VIS49827.2021.9623271},
ISSN={},
month={Oct},}
